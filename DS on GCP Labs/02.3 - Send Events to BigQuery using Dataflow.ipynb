{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"oauth2client.contrib.multistore_file\"\n",
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-08-29 16:06:59.140182. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import apache_beam as beam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-08-29 16:06:59.889724. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "RUNNER = \"Dataflow\"\n",
    "PROJECT = 'ksalama-gcp-playground'\n",
    "BUCKET = 'ksalama-gcs-demo'\n",
    "REGION = 'europe-west1'\n",
    "TOPIC = 'flights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-08-29 16:07:20.717033. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def to_bq_row(message):\n",
    "\n",
    "    data_row = message.data\n",
    "    return data_row\n",
    "  \n",
    "\n",
    "#print(exract_fields(\"101,2.0334,-856.06\"))\n",
    "  \n",
    "def run_flights_pipeline():\n",
    "    \n",
    "    job_name = 'ingest-flight-events-{}'.format(datetime.datetime.now().strftime('%y%m%d-%H%M%S'))\n",
    "    print 'Launching Dataflow job {}'.format(job_name)\n",
    "    print 'Check the Dataflow jobs on Google Cloud Console...'\n",
    "\n",
    "    TMP_DIR = 'gs://{}/data/flights'.format(BUCKET)\n",
    "\n",
    "    options = {\n",
    "        'staging_location': os.path.join(TMP_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(TMP_DIR, 'tmp'),\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'streaming': True,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True\n",
    "      }\n",
    "\n",
    "\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    source = beam.io.PubSubSource(\"projects/ksalama-gcp-playground/topics/flights\")\n",
    "    \n",
    "    p = beam.Pipeline(RUNNER, options=opts)\n",
    "      \n",
    "    sink = beam.io.BigQuerySink('{}:playground_ds.flight_events'.format(PROJECT), write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "    (\n",
    "      p | 'Read data from Pubsub' >> beam.io.Read(source)\n",
    "        | 'Get message' >> beam.Map(to_bq_row)\n",
    "        | 'Write to BigQuery' >> beam.io.Write(sink)\n",
    "    )\n",
    "\n",
    "    p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job ingest-flight-events-170829-160721\n",
      "Check the Dataflow jobs on Google Cloud Console...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pipeline has validations errors: \nStreaming pipelines are not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-04bab1dd07f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_flights_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-01b104c93a7d>\u001b[0m in \u001b[0;36mrun_flights_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPubSubSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"projects/ksalama-gcp-playground/topics/flights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRUNNER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0msink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBigQuerySink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}:playground_ds.flight_events'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_disposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBigQueryDisposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWRITE_APPEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/apache_beam/pipeline.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, runner, options, argv)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m       raise ValueError(\n\u001b[0;32m--> 134\u001b[0;31m           'Pipeline has validations errors: \\n' + '\\n'.join(errors))\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# Default runner to be used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pipeline has validations errors: \nStreaming pipelines are not supported."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-08-29 16:07:21.194032. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "run_flights_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-08-29 15:51:20.060037. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def to_table_row(line):\n",
    "    import csv\n",
    "    csv_fields = next(csv.reader([line]))\n",
    "    \n",
    "    try:\n",
    "      data_row = {\"airportId\":int(csv_fields[0]), \"longitude\":float(csv_fields[21]), \"latitude\":float(csv_fields[26])}\n",
    "    except:\n",
    "      data_row = {\"airportId\":-1, \"longitude\":1.1, \"latitude\":-1.1}\n",
    "    return data_row\n",
    "  \n",
    "\n",
    "#print(exract_fields(\"101,2.0334,-856.06\"))\n",
    "  \n",
    "def run_airports_pipeline():\n",
    "  \n",
    "  source = 'git-repo/04_streaming/simulate/airports.csv.gz'\n",
    "    \n",
    "  sink = beam.io.BigQuerySink('{}:playground_ds.airport_locations'.format(PROJECT), write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "    \n",
    "  p = beam.Pipeline(\"DirectRunner\")\n",
    "  \n",
    "  (\n",
    "    p | 'Read data from text file' >> beam.io.ReadFromText(source)\n",
    "      | 'Extract Fields' >> beam.Map(to_table_row)\n",
    "      | 'Write csv file to GCS' >> beam.io.Write(sink)\n",
    "  )\n",
    "\n",
    "  p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-08-29 15:51:20.453304. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "run_airports_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
