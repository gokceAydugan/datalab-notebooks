{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_file = 'data/train-data.csv'\n",
    "valid_data_file = 'data/valid-data.csv'\n",
    "test_data_file = 'data/test-data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to use the TF Estimator APIs\n",
    "\n",
    "1. Define dataset metadata\n",
    "\n",
    "2. Create TF feature columns based on metadata\n",
    "\n",
    "3. Define data input function to populate the features from the data source\n",
    "\n",
    "4. Create experiment: Initialise the estimator\n",
    "\n",
    "5. Run experiment: Supply train data, evaluation data, config, and params\n",
    "\n",
    "6. Evaluate the trained model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HEADER = ['pickup_datetime',\n",
    "          'pickup_dayofweek',\n",
    "          'pickup_hour',\n",
    "          'pickup_longitude',\n",
    "          'pickup_latitude',\n",
    "          'dropoff_longitude',\n",
    "          'dropoff_latitude', \n",
    "          'passenger_count',\n",
    "          'fare_amount']\n",
    "\n",
    "\n",
    "DEFAULTS = [['NULL'],['NULL'],[-1], [-74.0], [40.0], [-74.0], [40.7], [-1],[-.1]]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = ['pickup_longitude', \n",
    "                         'pickup_latitude',\n",
    "                         'dropoff_longitude', \n",
    "                         'dropoff_latitude', \n",
    "                         'passenger_count']\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = []\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "TARGET_NAME = 'fare_amount'\n",
    "\n",
    "UNUSED_FEATURE_NAMES = set(HEADER) - set(FEATURE_NAMES) - set([TARGET_NAME])\n",
    "\n",
    "print(\"Numeric features: {}\".format(NUMERIC_FEATURE_NAMES))\n",
    "print(\"Categorical features: {}\".format(CATEGORICAL_FEATURE_NAMES))\n",
    "print(\"Target: {}\".format(TARGET_NAME))\n",
    "print(\"Unused features: {}\".format(UNUSED_FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_feature_columns():\n",
    "\n",
    "    numeric_columns = list(map(lambda feature_name: tf.feature_column.numeric_column(feature_name, dtype=tf.float32),\n",
    "                               NUMERIC_FEATURE_NAMES))\n",
    "\n",
    "    feature_columns = numeric_columns\n",
    "    \n",
    "    return feature_columns\n",
    "\n",
    "# Test create_feature_columns()\n",
    "feature_columns = create_feature_columns() \n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a data input function\n",
    "\n",
    "This function creates tensorflow data structures (i.e., dictionary of tensors) from Pandas Dataframe... (think about scalability; resultant dataframe needs to fit the memory!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pandas_input_fn(data_frame):\n",
    "  \n",
    "  \n",
    "    continuous_features = {f: tf.constant(data_frame[f].values, dtype=tf.float32) for f in NUMERIC_FEATURE_NAMES}\n",
    "\n",
    "    features = continuous_features\n",
    " \n",
    "    target = tf.constant(data_frame[TARGET_NAME].values, dtype=tf.float32)\n",
    "\n",
    "    return features, target\n",
    "  \n",
    "# Test pandas_input_fn()\n",
    "df_train = pd.read_csv(train_data_file, header=None, names=HEADER)\n",
    "features,target = pandas_input_fn(df_train)\n",
    "feature_colum_names = list(features.keys())\n",
    "print(feature_colum_names)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluation_metrics={\n",
    "    'rmse': tf.contrib.learn.MetricSpec(metric_fn=tf.metrics.root_mean_squared_error)\n",
    "    }\n",
    "\n",
    "def print_evaluation(estimator):\n",
    "    \n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    \n",
    "    train_metric = estimator.evaluate(input_fn = lambda: pandas_input_fn(df_train), \n",
    "                                        steps=1, \n",
    "                                        metrics = evaluation_metrics)\n",
    "\n",
    "    valid_metric = estimator.evaluate(input_fn = lambda: pandas_input_fn(df_valid), \n",
    "                                        steps=1, \n",
    "                                        metrics = evaluation_metrics)\n",
    "\n",
    "    test_metric = estimator.evaluate(input_fn = lambda: pandas_input_fn(df_test), \n",
    "                                       steps=1, \n",
    "                                       metrics = evaluation_metrics)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"train metric:{}\".format(train_metric))\n",
    "    print(\"valid metric:{}\".format(valid_metric))\n",
    "    print(\"test metric:{}\".format(test_metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiement with Linear Regression Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_linear_regression(run_config,hparams):\n",
    "  \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = hparams.learning_rate)\n",
    "  \n",
    "    estimator = tf.contrib.learn.LinearRegressor(\n",
    "        feature_columns=feature_columns,\n",
    "        optimizer = optimizer,\n",
    "        config=run_config)\n",
    "      \n",
    "    experiment =  tf.contrib.learn.Experiment(estimator=estimator, \n",
    "                                   train_steps = hparams.training_steps,\n",
    "                                   train_input_fn = lambda: pandas_input_fn(df_train), \n",
    "                                   eval_input_fn =lambda: pandas_input_fn(df_valid),\n",
    "                                   eval_metrics = evaluation_metrics\n",
    "                                  )\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set params and run experiemnt - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframes\n",
    "df_train = pd.read_csv('data/train-data.csv', header=None, names=HEADER)\n",
    "df_valid = pd.read_csv('data/valid-data.csv', header=None, names=HEADER)\n",
    "df_test = pd.read_csv('data/test-data.csv', header=None, names=HEADER)\n",
    "\n",
    "# Define algorithm and experiment parameters\n",
    "hparams  = tf.contrib.training.HParams(training_steps=10000, learning_rate=0.00001)\n",
    "\n",
    "# Set trained model location\n",
    "model_dir = \"trained_models/linear_regression_model\"\n",
    "\n",
    "# Clear model directory\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "    model_dir=model_dir\n",
    ")\n",
    "\n",
    "# Run experiement\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.contrib.learn.learn_runner.run(experiment_fn = experiment_linear_regression, \n",
    "                               run_config = run_config,\n",
    "                               schedule=\"train_and_evaluate\",\n",
    "                               hparams=hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained Model - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_model = tf.contrib.learn.LinearRegressor(\n",
    "        feature_columns=feature_columns,\n",
    "        config=run_config)\n",
    "\n",
    "print_evaluation(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create another experiement using Deep Neural Networks (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_dnn_regression(run_config,hparams):\n",
    "    \n",
    "    dnn_estimator = tf.contrib.learn.DNNRegressor(\n",
    "            feature_columns = feature_columns,\n",
    "            hidden_units=hparams.hidden_units,\n",
    "            config = run_config\n",
    "    )\n",
    "    \n",
    "    experiment =  tf.contrib.learn.Experiment(estimator = dnn_estimator, \n",
    "                                     train_steps = hparams.training_steps,\n",
    "                                     train_input_fn = lambda: pandas_input_fn(df_train),\n",
    "                                     eval_input_fn =lambda: pandas_input_fn(df_valid),\n",
    "                                     eval_metrics = evaluation_metrics\n",
    "                                    )\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set params and run experiemnt - DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset into dataframes\n",
    "df_train = pd.read_csv('data/train-data.csv', header=None, names=HEADER)\n",
    "df_valid = pd.read_csv('data/valid-data.csv', header=None, names=HEADER)\n",
    "df_test = pd.read_csv('data/test-data.csv', header=None, names=HEADER)\n",
    "\n",
    "# Set params\n",
    "hparams  = tf.contrib.training.HParams(training_steps=10000,\n",
    "                                       hidden_units=[32, 8, 2])\n",
    "model_dir = \"trained_models/dnn_regression_model\"\n",
    "\n",
    "# Clear model directory# Clear model directory\n",
    "shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(\n",
    "    model_dir=model_dir\n",
    ")\n",
    "\n",
    "# Run the experiment\n",
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "tf.contrib.learn.learn_runner.run(experiment_fn = experiment_dnn_regression, \n",
    "                               run_config = run_config,\n",
    "                               schedule=\"train_and_evaluate\",\n",
    "                               hparams=hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained Model - DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dnn_model = tf.contrib.learn.DNNRegressor(\n",
    "            feature_columns = feature_columns,\n",
    "            hidden_units=hparams.hidden_units,\n",
    "            config = run_config\n",
    "    )\n",
    "\n",
    "print_evaluation(dnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results so far..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame({\n",
    "              'Method' : pd.Series(['Basline', 'Linear Reg', 'DNN', ' ---', '----', '-----']),\n",
    "              'RMSE': pd.Series([8.89, 11.15, 14.94, 0, 0, 0.0]) })\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.barplot(data=df, x='Method', y='RMSE')\n",
    "ax.set_ylabel('RMSE (dollars)')\n",
    "ax.set_xlabel('Method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
