{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"oauth2client.contrib.multistore_file\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0.dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-10-10 18:42:49.314738. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from google.cloud import pubsub\n",
    "import json\n",
    "import apache_beam as beam\n",
    "import os\n",
    "print(beam.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-10-10 18:49:23.765724. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "RUNNER = \"Dataflow\"\n",
    "PROJECT = 'ksalama-gcp-playground'\n",
    "DATASET = 'playground_ds'\n",
    "TABLE = 'taxi_trips'\n",
    "STG_BUCKET = 'stagging-ksalama-gcs-cloudml'\n",
    "REGION = 'europe-west1'\n",
    "TOPIC = 'taxi-trips'\n",
    "SUBSCRIPTION='taxi-trips-sub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Dataflow Stream Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/ksalama-gcp-playground/subscriptions/taxi_trips-sub\n",
      "('playground_ds', 'taxi_trips')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-10-10 18:42:50.874364. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "pubsub_subscription = \"projects/{}/subscriptions/{}\".format(PROJECT,SUBSCRIPTION)\n",
    "pubsub_topic = \"projects/{}/topics/{}\".format(PROJECT,TOPIC)\n",
    "\n",
    "print(pubsub_subscription)\n",
    "print(DATASET,TABLE)\n",
    "\n",
    "def process_events(message):\n",
    "    data_row = message.data\n",
    "    #preform all yor data processing, transformation, calling external APIs, etc.\n",
    "    return data_row\n",
    "  \n",
    "def run_taxi_trips_pipeline():\n",
    "    \n",
    "    job_name = 'ingest-taxi-trips-{}'.format(datetime.datetime.now().strftime('%y%m%d-%H%M%S'))\n",
    "    print 'Launching Dataflow job {}'.format(job_name)\n",
    "    print 'Check the Dataflow jobs on Google Cloud Console...'\n",
    "\n",
    "    STG_DIR = 'gs://{}/taxi-fare'.format(STG_BUCKET)\n",
    "\n",
    "    options = {\n",
    "        'staging_location': os.path.join(STG_DIR, 'tmp', 'staging'),\n",
    "        'temp_location': os.path.join(STG_DIR, 'tmp'),\n",
    "        'job_name': job_name,\n",
    "        'project': PROJECT,\n",
    "        'streaming': True,\n",
    "        'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "        'no_save_main_session': True\n",
    "      }\n",
    "\n",
    "\n",
    "    opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "    \n",
    "    pipeline = beam.Pipeline(RUNNER, options=opts)\n",
    "      \n",
    "    (\n",
    "      pipeline | 'Read data from PubSub' >> beam.io.ReadStringsFromPubSub(subscription=pubsub_subscription) \n",
    "               | 'Process message' >> beam.Map(process_events) # filter, window, group, aggregate \n",
    "               | 'Write to BigQuery' >> beam.io.WriteToBigQuery(project=PROJECT, dataset=DATASET,table=TABLE)\n",
    "    )\n",
    "\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job ingest-taxi-trips-171010-184251\n",
      "Check the Dataflow jobs on Google Cloud Console...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/apache_beam/utils/annotations.py:99: DeprecationWarning: options is deprecated since First stable release.. References to <pipeline>.options will not be supported\n",
      "  warnings.warn(message, warning_type)\n",
      "/usr/local/lib/python2.7/dist-packages/apache_beam/coders/typecoders.py:135: UserWarning: Using fallback coder for typehint: Any.\n",
      "  warnings.warn('Using fallback coder for typehint: %r.' % typehint)\n",
      "/usr/local/lib/python2.7/dist-packages/apache_beam/io/gcp/gcsio.py:113: DeprecationWarning: object() takes no parameters\n",
      "  super(GcsIO, cls).__new__(cls, storage_client))\n",
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-10-10 18:42:51.619907. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "run_taxi_trips_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-10-10 18:43:03.343734. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "csv_header_names = ['trip_datetime', 'pickup_dayofweek', 'pickup_hour','pickup_lon', 'pickup_lat', 'dropoff_lon', 'dropoff_lat', 'passenger_count', 'fare_amount']\n",
    "header_names = ['trip_datetime', 'pickup_lon', 'pickup_lat', 'dropoff_lon', 'dropoff_lat', 'passenger_count', 'fare_amount']\n",
    "\n",
    "dataset = pd.read_csv('data/train-data.csv', header=None, names=csv_header_names)[header_names]\n",
    "def get_data_points(count=10):\n",
    "  \n",
    "    data_points = []\n",
    "  \n",
    "    instances = dataset.sample(n=count).values\n",
    "  \n",
    "    for row in instances:\n",
    "        data_point = dict()\n",
    "    \n",
    "    for i in range(len(row)):\n",
    "        data_point[header_names[i]] = row[i]\n",
    "     \n",
    "    data_points.append(data_point)\n",
    "      \n",
    "    return data_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Data Points to Pub/Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pub/sub topic taxi-trips is up and running\n",
      "\n",
      "Batch 0 was sent. Last Message was: {\"pickup_lon\": -74.0049514771, \"fare_amount\": 7.5, \"dropoff_lon\": -73.9918060303, \"passenger_count\": 1, \"pickup_lat\": 40.7466087341, \"trip_datetime\": \"2015-06-03 13:33:43\", \"dropoff_lat\": 40.7645149231}\n",
      "\n",
      "Batch 1 was sent. Last Message was: {\"pickup_lon\": -73.9788665771, \"fare_amount\": 33.33, \"dropoff_lon\": -73.8710021973, \"passenger_count\": 1, \"pickup_lat\": 40.7540245056, \"trip_datetime\": \"2015-02-06 12:10:20\", \"dropoff_lat\": 40.7741966248}\n",
      "\n",
      "Batch 2 was sent. Last Message was: {\"pickup_lon\": -74.00728607180001, \"fare_amount\": 11.5, \"dropoff_lon\": -74.0135498047, \"passenger_count\": 1, \"pickup_lat\": 40.7434463501, \"trip_datetime\": \"2015-02-15 01:39:24\", \"dropoff_lat\": 40.7155380249}\n",
      "\n",
      "Batch 3 was sent. Last Message was: {\"pickup_lon\": -73.9684677124, \"fare_amount\": 6.5, \"dropoff_lon\": -73.98252868649999, \"passenger_count\": 5, \"pickup_lat\": 40.7676086426, \"trip_datetime\": \"2015-04-13 10:50:08\", \"dropoff_lat\": 40.769199371300004}\n",
      "\n",
      "Batch 4 was sent. Last Message was: {\"pickup_lon\": -74.0083618164, \"fare_amount\": 10.5, \"dropoff_lon\": -73.9944229126, \"passenger_count\": 1, \"pickup_lat\": 40.712184906, \"trip_datetime\": \"2015-06-24 15:57:36\", \"dropoff_lat\": 40.7263832092}\n",
      "\n",
      "Batch 5 was sent. Last Message was: {\"pickup_lon\": -73.9856719971, \"fare_amount\": 15.5, \"dropoff_lon\": -73.963508606, \"passenger_count\": 1, \"pickup_lat\": 40.727016449000004, \"trip_datetime\": \"2015-03-08 23:25:56\", \"dropoff_lat\": 40.6921424866}\n",
      "\n",
      "Batch 6 was sent. Last Message was: {\"pickup_lon\": -73.9853897095, \"fare_amount\": 12.5, \"dropoff_lon\": -73.9759750366, \"passenger_count\": 5, \"pickup_lat\": 40.7683029175, \"trip_datetime\": \"2015-03-12 13:23:59\", \"dropoff_lat\": 40.7515525818}\n",
      "\n",
      "Batch 7 was sent. Last Message was: {\"pickup_lon\": -73.9583587646, \"fare_amount\": 6.5, \"dropoff_lon\": -73.9629516602, \"passenger_count\": 1, \"pickup_lat\": 40.8008537292, \"trip_datetime\": \"2015-04-25 10:14:01\", \"dropoff_lat\": 40.8042869568}\n",
      "\n",
      "Batch 8 was sent. Last Message was: {\"pickup_lon\": -73.9906539917, \"fare_amount\": 9.0, \"dropoff_lon\": -74.0055770874, \"passenger_count\": 1, \"pickup_lat\": 40.7510223389, \"trip_datetime\": \"2015-05-28 19:04:25\", \"dropoff_lat\": 40.725673675500005}\n",
      "\n",
      "Batch 9 was sent. Last Message was: {\"pickup_lon\": -74.0008850098, \"fare_amount\": 3.0, \"dropoff_lon\": -74.0045013428, \"passenger_count\": 1, \"pickup_lat\": 40.7416954041, \"trip_datetime\": \"2015-05-06 19:03:14\", \"dropoff_lat\": 40.7431259155}\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-10-10 18:49:32.305917. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "iterations = 10\n",
    "sleep_time = 1\n",
    "\n",
    "client = pubsub.Client()\n",
    "topic = client.topic(TOPIC)\n",
    "\n",
    "if not topic.exists():\n",
    "    print ('Creating pub/sub topic {}...'.format(TOPIC))\n",
    "    topic.create()\n",
    "\n",
    "print ('Pub/sub topic {} is up and running'.format(TOPIC))\n",
    "print(\"\")\n",
    "\n",
    "for i in range(iterations):\n",
    "\n",
    "    data_points = get_data_points(batch_size)\n",
    "    \n",
    "    for data_point in data_points:\n",
    "\n",
    "        source_id = str(abs(hash(str(data_point))) % (10 ** 10))\n",
    "        source_timestamp = datetime.datetime.now().strftime(TIME_FORMAT)\n",
    "        message = json.dumps(data_point)\n",
    "        topic.publish(message=message, source_id = source_id, source_timestamp=source_timestamp)\n",
    "\n",
    "    print(\"Batch {} was sent. Last Message was: {}\".format(i, message))\n",
    "    print(\"\")\n",
    "\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume PubSub Topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('source_id', u'6121392541')\n",
      "('source_timestamp:', u'2017-10-10 18:49:42')\n",
      "\n",
      "{\"pickup_lon\": -73.9906539917, \"fare_amount\": 9.0, \"dropoff_lon\": -74.0055770874, \"passenger_count\": 1, \"pickup_lat\": 40.7510223389, \"trip_datetime\": \"2015-05-28 19:04:25\", \"dropoff_lat\": 40.725673675500005}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/simplejson/encoder.py:291: DeprecationWarning: Interpreting naive datetime as local 2017-10-10 18:50:02.123470. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "client = pubsub.Client()\n",
    "topic = client.topic(TOPIC)\n",
    "subscription = topic.subscription(SUBSCRIPTION)\n",
    "message = subscription.pull()\n",
    "\n",
    "# print(message[0][1].source_timestamp)\n",
    "print(\"source_id\", message[0][1].attributes[\"source_id\"])\n",
    "print(\"source_timestamp:\", message[0][1].attributes[\"source_timestamp\"])\n",
    "print(\"\")\n",
    "print(message[0][1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
